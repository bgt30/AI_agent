import os
import streamlit as st
from dotenv import load_dotenv
from googleapiclient.discovery import build
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import re

# Load environment variables
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# Initialize GPT-4o-mini model
llm = ChatOpenAI(
    temperature=0,
    model_name="gpt-4o-mini",
    openai_api_key=openai_api_key
)

youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

# Classification prompt template
classify_prompt = PromptTemplate(
    input_variables=["query"],
    template="""
    ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥(AI)ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€ì„ ì œê³µí•˜ê³  ìœ íŠœë¸Œ ë™ì˜ìƒì„ ì¶”ì²œí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    ê´€ë ¨ì„± íŒë‹¨:
       ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{query}"
       - ì§ˆë¬¸ì´ AI, ì¸ê³µì§€ëŠ¥ ë˜ëŠ” ê·¸ ì‘ìš© ë¶„ì•¼ì™€ ì§ì ‘ì  í˜¹ì€ ê°„ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
       - ê´€ë ¨ì´ ìˆë‹¤ë©´ "AI-RELATED"ë¡œ ì‹œì‘í•˜ì„¸ìš”.
       - ê´€ë ¨ì´ ì—†ë‹¤ë©´ "NOT-AI-RELATED"ë¡œ ì‹œì‘í•˜ê³ , ë” ì´ìƒ ì§„í–‰í•˜ì§€ ë§ˆì„¸ìš”.
    """
)
classify_chain = LLMChain(llm=llm, prompt=classify_prompt)

# TF-IDF and cosine similarity functions
def extract_keywords(text):
    # Remove special characters
    text = re.sub(r'[^\w\s]', '', text)
    return text.lower()

# ì¸ê¸° ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
def get_top_comments(video_id, max_comments=5):
    try:
        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=max_comments,
            order="relevance"
        )
        response = request.execute()
        comments = [
            item["snippet"]["topLevelComment"]["snippet"]["textOriginal"]
            for item in response["items"]
        ]
        return comments
    except Exception:
        return ["ëŒ“ê¸€ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
def search_youtube_videos_with_comments(query, max_results=5, max_comments=3):
    # Refine query with TF-IDF
    refined_query = extract_keywords(query)
    tfidf_vectorizer = TfidfVectorizer()
    tfidf_matrix = tfidf_vectorizer.fit_transform([refined_query])

    request = youtube.search().list(
        part="snippet",
        q=query,
        type="video",
        maxResults=max_results,
        order="viewCount"
    )
    response = request.execute()
    videos = []
    if "items" in response:
        for item in response["items"]:
            title = item["snippet"]["title"]
            description = item["snippet"]["description"]
            video_id = item["id"]["videoId"]

            # Vectorize title and description
            video_text = title + " " + description
            video_text = extract_keywords(video_text)
            video_tfidf_matrix = tfidf_vectorizer.transform([video_text])

            # Calculate cosine similarity
            similarity = cosine_similarity(tfidf_matrix, video_tfidf_matrix)[0][0]

            # Get top comments
            comments = get_top_comments(video_id, max_comments)

            videos.append({
                "title": title,
                "description": description,
                "video_id": video_id,
                "similarity": similarity,
                "comments": comments
            })

    # Sort by similarity
    videos = sorted(videos, key=lambda x: x["similarity"], reverse=True)
    return videos

# Streamlit UI ì„¤ì •
st.title("AI YouTube Video Recommendation")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”! ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    # ì¢…ë£Œ ì¡°ê±´ ì²˜ë¦¬
    if user_input.lower() == "exit":
        st.info("ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # RAG ëª¨ë¸ í˜¸ì¶œ
        with st.chat_message("assistant"):
            try:
                # GPT ëª¨ë¸ë¡œ ê´€ë ¨ì„± íŒë‹¨
                classification = classify_chain.run({"query": user_input})
                if classification.startswith("NOT-AI-RELATED"):
                    error_message = "AI ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”"
                    st.subheader(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
                else:
                    # ìœ íŠœë¸Œ ê²€ìƒ‰ ì‹¤í–‰
                    videos = search_youtube_videos_with_comments(user_input)
                    if videos:
                        st.subheader("ğŸ” ê´€ë ¨ ìœ íŠœë¸Œ ë™ì˜ìƒ ì¶”ì²œ:")
                        assistant_response = ""
                        for video in videos:
                            # ìœ íŠœë¸Œ ë™ì˜ìƒ ì‚½ì…
                            st.video(f"https://www.youtube.com/watch?v={video['video_id']}")
                            
                            # ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ (ì„¤ëª…ë§Œ ë‚¨ê¹€)
                            video_info = f"**ì„¤ëª…:** {video['description']}\n"
                            
                            # ëŒ“ê¸€ ì •ë³´
                            comments_info = "\n".join([f"  - {comment}" for comment in video["comments"]])
                            
                            # Combine all information
                            full_info = f"{video_info}\n\n**ëŒ“ê¸€:**\n{comments_info}\n\n---"
                            
                            # Append to assistant response
                            assistant_response += full_info
                            
                            # Display video information and comments in Streamlit
                            st.markdown(full_info)
                        
                        # Append the assistant's response to the chat history
                        st.session_state.messages.append({"role": "assistant", "content": assistant_response})

                    else:
                        error_message = "ê´€ë ¨ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        st.subheader(error_message)
                        st.session_state.messages.append({"role": "assistant", "content": error_message})

            except Exception as e:
                st.error(f"RAG í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")